{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Import Python packages \n",
    "import pandas as pd\n",
    "import cassandra\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Creating list of filepaths to process original event csv data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# checking your current working directory\n",
    "print(os.getcwd())\n",
    "\n",
    "# Get your current folder and subfolder event_data\n",
    "filepath = os.getcwd() + '/event_data'\n",
    "\n",
    "# Create a for loop to create a list of files and collect each filepath\n",
    "for root, dirs, files in os.walk(filepath):\n",
    "    #print('root: ', root, '\\ndirs: ', dirs, '\\nfiles: ', files)\n",
    "    \n",
    "# join the file path and roots with the subdirectories using glob\n",
    "    file_path_list = glob.glob(os.path.join(filepath,'*'))\n",
    "    print(file_path_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Processing the files to create the data file csv that will be used for Apache Casssandra tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# initiating an empty list of rows that will be generated from each file\n",
    "full_data_rows_list = [] \n",
    "    \n",
    "# for every filepath in the file path list \n",
    "for f in file_path_list: \n",
    "    # read the csv file in the current filepath\n",
    "    with open(f, 'r', encoding = 'utf8', newline='') as csvfile: \n",
    "        csvreader = csv.reader(csvfile) \n",
    "        next(csvreader)        \n",
    "        # for each data row in the csv file, append it      \n",
    "        for line in csvreader:\n",
    "            full_data_rows_list.append(line) \n",
    "print(\"Total Number of Rows: \", len(full_data_rows_list))\n",
    "\n",
    "# creating a smaller event data csv file called event_datafile_full csv that will be used to insert data into the \\\n",
    "# Apache Cassandra tables\n",
    "csv.register_dialect('myDialect', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "with open('event_datafile_new.csv', 'w', encoding = 'utf8', newline='') as f:\n",
    "    writer = csv.writer(f, dialect='myDialect')\n",
    "    writer.writerow(['artist','firstName','gender','itemInSession','lastName','length',\\\n",
    "                'level','location','sessionId','song','userId'])\n",
    "    for row in full_data_rows_list:\n",
    "        if (row[0] == ''):\n",
    "            continue\n",
    "        writer.writerow((row[0], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[12], row[13], row[16]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# check the number of rows in your csv file\n",
    "with open('event_datafile_new.csv', 'r', encoding = 'utf8') as f:\n",
    "    print(sum(1 for line in f))"
   ]
  },
  {
   "source": [
    "## Creating Apache Cassandra cluster"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from cassandra.cluster import Cluster\n",
    "cluster = Cluster()\n",
    "session = cluster.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# create Keyspace\n",
    "\n",
    "try:\n",
    "    session.execute(\"\"\"\n",
    "    CREATE KEYSPACE IF NOT EXISTS udacity \n",
    "    WITH REPLICATION = \n",
    "    { 'class' : 'SimpleStrategy', 'replication_factor' : 1 }\"\"\"\n",
    ")\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# set keyspace\n",
    "\n",
    "try:\n",
    "    session.set_keyspace('udacity')\n",
    "except exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Creating queries to ask the following three questions of the data\n",
    "\n",
    "1. Give me the artist, song title and song's length in the music app history that was heard during  sessionId = 338, and itemInSession  = 4\n",
    "\n",
    "2. Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182\n",
    "    \n",
    "3. Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 1.\n",
    "\n",
    "Because the question is asking for the name of the artist, the song's title, and the song's length, it is apparent that our data model will have to include the **artist_title**, **song_title**, and **song_length** columns from **event_datafile_new.csv**. In our query, we will use the `SELECT` statement to retreive these values.\n",
    "\n",
    "Because the question is asking to search for these values based on a specified **sessionId** and **itemInSession**, we will need to include these colums from **event_datafile_new.csv** in our data model as well, and we will use these columns to partition the data. In our query, will use the `WHERE` clause to specify that we want to search on these columns, which will be our partition.\n",
    "\n",
    "We will call the data model, or table, *music_history*.\n",
    "\n",
    "With all this in mind, we get the following query:\n",
    "\n",
    "`SELECT artist_name, song_title, song_length FROM music_history WHERE sessionID=338 AND itemInSession=4`\n",
    "\n",
    "To create our table that is rightly partioned by the **sessionId** and **itemInSession** columns, we will set our `PRIMARY KEY` to these columns by using **sessionId** as our `PARTITION KEY` and **itemInSession** as our `CLUSTERING KEY`:\n",
    "\n",
    "`CREATE TABLE IF NOT EXISTS music_history\n",
    "(\n",
    "    sessionId int,\n",
    "    itemInSession int,\n",
    "    artist_name text, \n",
    "    song_title text, \n",
    "    song_length float, \n",
    "    PRIMARY KEY (sessionId, itemInSession)\n",
    ")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Query 1:  Give me the artist, song title and song's length in the music app history that was heard during \\\n",
    "## sessionId = 338, and itemInSession = 4\n",
    "\n",
    "query = \"CREATE TABLE IF NOT EXISTS music_history \"\n",
    "query = query + \"(sessionId int, itemInSession int, artist_name text, song_title text, song_length float, PRIMARY KEY (sessionId, itemInSession))\"\n",
    "\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Populating music_history table with data from event_datafile_new.csv\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        query = \"INSERT INTO music_history (sessionId, itemInSession, artist_name, song_title, song_length)\"\n",
    "        query = query + \"VALUES (%s, %s, %s, %s, %s)\"\n",
    "        session.execute(query, (int(line[8]), int(line[3]), line[0], line[9], float(line[5])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Executing Query 1\n",
    "\n",
    "query = \"SELECT artist_name, song_title, song_length FROM music_history WHERE sessionID=139 AND itemInSession=1\"\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "print(pd.DataFrame(list(rows)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 2.\n",
    "\n",
    "Because the question is asking for the name of the artist, the song's title, and the user's full name, it is apparent that our data model will have to include the **artist_title**, **song_title**, **firstName** and **lastName** columns from **event_datafile_new.csv**. In our query, we will use the `SELECT` statement to retreive these values.\n",
    "\n",
    "Because the question is asking to search for these values based on a specified **userId** and **sessionId**, we will need to include these colums from **event_datafile_new.csv** in our data model as well, and we will use these columns to partition the data. In addition, the question asks to sort the songs by **itemInSession**. To achieve that, we will need to use **itemInSession** to partition our data (will explain why later), but these are not needed in our `SELECT` query. In our query, will use the `WHERE` clause to specify that we want to search only on the **userId** and **sessionId** columns of our partition.\n",
    "\n",
    "We will call the data model, or table, *user_history*.\n",
    "\n",
    "With all this in mind, we get the following query:\n",
    "\n",
    "`SELECT artist_name, song_title, firstName, lastName FROM user_history WHERE userId=10 AND sessionId=182`\n",
    "\n",
    "To create our table that is rightly partioned by the **userId**, **sessionId**, and **itemInSession** columns, we will do a couple things to create our `PRIMARY KEY`:\n",
    "- Group **userId** and **sessionId** together as our `PARTITION KEY`\n",
    "- Set **itemInSession** as our `CLUSTERING KEY`\n",
    "\n",
    "\n",
    "`CREATE TABLE IF NOT EXISTS music_history\n",
    "(\n",
    "    userId int, \n",
    "    sessionID int, \n",
    "    itemInSession int, \n",
    "    song_title text, \n",
    "    artist_name text,\n",
    "    firstName text, \n",
    "    lastName text, \n",
    "    PRIMARY KEY ((userId, sessionId), itemInSession)\n",
    ")`\n",
    "\n",
    "The reason we need **itemInSession** included in our partition, is because Apache Cassandra automaically groups data by the order they are listed in the `PRIMARY KEY` and sorts them in ascending order. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Query 2: Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name)\\\n",
    "## for userid = 10, sessionid = 182\n",
    "\n",
    "query = \"CREATE TABLE IF NOT EXISTS user_history \"\n",
    "query = query + \"(userId int, sessionID int, itemInSession int, song_title text, artist_name text, firstName text, lastName text, PRIMARY KEY ((userId, sessionId), itemInSession))\"\n",
    "\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Populating music_history table with data from event_datafile_new.csv\n",
    "\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        query = \"INSERT INTO user_history (userId, sessionID, itemInSession, song_title, artist_name, firstName, lastName)\"\n",
    "        query = query + \"VALUES (%s, %s, %s, %s, %s, %s, %s)\"\n",
    "        session.execute(query, (int(line[10]), int(line[8]), int(line[3]), line[9], line[0], line[1], line[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Executing Query 2\n",
    "\n",
    "query = \"SELECT artist_name, song_title, firstName, lastName FROM user_history WHERE userId=8 AND sessionId=139\"\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "print(pd.DataFrame(list(rows)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 3.\n",
    "\n",
    "Because the question is asking for full names of users, it is apparent that our data model will have to include the **firstName** and **lastName** columns from **event_datafile_new.csv**. In our query, we will use the `SELECT` statement to retreive these values.\n",
    "\n",
    "Because the question is asking to search for these values based on a specified song title, we will need to include the **song_title** column from **event_datafile_new.csv** in our data model as well, and we will use this column to partition the data. However, the song title alone won't be sufficient for giving each row of a data unique `PRIMARY KEY`, as several users can listen to the same song. So, to make sure each row has a unique `PRIMARY KEY`, we will need to include the **userId** column as well, but it will not be needed for our query. We will only search on the **song_title** column of our partition using the `WHERE` clause.\n",
    "\n",
    "We will call the data model, or table, *song_playlist_session*.\n",
    "\n",
    "With all this in mind, we get the following query:\n",
    "\n",
    "`SELECT firstName, lastName FROM song_playlist_session WHERE song_title='All Hands Against His Own'`\n",
    "\n",
    "To create our table that is rightly partioned by the **song_title** and **userId** columns, we will do a couple things to create our `PRIMARY KEY`:\n",
    "- Set **song_title** as our `PARTITION KEY`\n",
    "- Set **userId** as our `CLUSTERING KEY`\n",
    "\n",
    "`CREATE TABLE IF NOT EXISTS song_playlist_session\n",
    "(\n",
    "    song_title text,\n",
    "    userId,\n",
    "    firstName text, \n",
    "    lastName text, \n",
    "    PRIMARY KEY (song_title, userId)\n",
    ")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Query 3: Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "\n",
    "query = \"CREATE TABLE IF NOT EXISTS song_playlist_session \"\n",
    "query = query + \"(song_title text, userId int, firstName text, lastName text, PRIMARY KEY (song_title, userId))\"\n",
    "\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Populating music_history table with data from event_datafile_new.csv\n",
    "\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        query = \"INSERT INTO song_playlist_session (song_title, userId, firstName, lastName)\"\n",
    "        query = query + \"VALUES (%s, %s, %s, %s)\"\n",
    "        session.execute(query, (line[9], int(line[10]), line[1], line[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Executing Query 3\n",
    "query = \"SELECT firstName, lastName FROM song_playlist_session WHERE song_title='Pump It'\"\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "print(pd.DataFrame(list(rows)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Drop the tables before closing out the sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    session.execute('DROP TABLE IF EXISTS music_history')\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "try:\n",
    "    session.execute('DROP TABLE IF EXISTS user_history')\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    \n",
    "try:\n",
    "    session.execute('DROP TABLE IF EXISTS song_playlist_session')\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Close the session and cluster connectionÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "session.shutdown()\n",
    "cluster.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python373jvsc74a57bd0398dc28c06ad810e77de546bbdfa897a6ee0b83e59a5207339dda01a7843e01d",
   "display_name": "Python 3.7.3 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}